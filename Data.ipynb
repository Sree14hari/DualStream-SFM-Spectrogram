{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61a946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing SPLIT: TRAIN\n",
      "   üîπ Cysts_Structural: 342 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     Processing Cysts_Structural:   0%|          | 0/342 [00:00<?, ?it/s]c:\\Users\\sreeh\\miniconda3\\envs\\your_env_name\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ Dysarthia: 662 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ Laryngitis: 672 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üî∏ Vox senilis: 1488 -> Capping at 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üî∏ parkinson: 10786 -> Capping at 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ spasmodische_dysphonie: 306 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing SPLIT: VAL\n",
      "   üîπ Cysts_Structural: 21 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ Dysarthia: 41 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ Laryngitis: 42 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ Vox senilis: 93 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üî∏ parkinson: 674 -> Capping at 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ spasmodische_dysphonie: 19 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing SPLIT: TEST\n",
      "   üîπ Cysts_Structural: 22 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ Dysarthia: 42 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ Laryngitis: 42 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ Vox senilis: 93 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üî∏ parkinson: 675 -> Capping at 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   üîπ spasmodische_dysphonie: 20 (Kept all)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done! Data saved to 'processed_data'\n",
      "üìù Index saved to 'dataset_final.csv'\n",
      "   Total Files: 4817\n",
      "split\n",
      "train    3982\n",
      "test      419\n",
      "val       416\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_ROOT = \"RawDataset\"         # Must contain train/ test/ val subfolders\n",
    "OUTPUT_ROOT = \"processed_data\"  # Where clean files will go\n",
    "CSV_FILENAME = \"dataset_final.csv\"\n",
    "\n",
    "TARGET_SR = 16000     # Audio-MAE requirement\n",
    "MAX_FILES_TRAIN = 1000 # Limit for TRAIN folders\n",
    "MAX_FILES_TEST = 200   # Limit for TEST/VAL (usually we want fewer here)\n",
    "TRIM_SILENCE = True   \n",
    "\n",
    "def preprocess_audio(file_path, output_path):\n",
    "    try:\n",
    "        # 1. Load & Resample\n",
    "        y, sr = librosa.load(file_path, sr=TARGET_SR, mono=True)\n",
    "        \n",
    "        # 2. Trim Silence\n",
    "        if TRIM_SILENCE:\n",
    "            y, _ = librosa.effects.trim(y, top_db=20)\n",
    "            \n",
    "        # 3. Peak Normalization (-1 dB)\n",
    "        max_val = np.max(np.abs(y))\n",
    "        if max_val > 0:\n",
    "            y = y / max_val * 0.9\n",
    "            \n",
    "        # 4. Save\n",
    "        sf.write(output_path, y, sr)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INPUT_ROOT):\n",
    "        print(f\"‚ùå Error: '{INPUT_ROOT}' not found.\")\n",
    "        return\n",
    "\n",
    "    processed_records = []\n",
    "    \n",
    "    # We look for these 3 specific subfolders\n",
    "    splits = ['train', 'val', 'test']\n",
    "    \n",
    "    for split_name in splits:\n",
    "        split_path = os.path.join(INPUT_ROOT, split_name)\n",
    "        \n",
    "        if not os.path.exists(split_path):\n",
    "            print(f\"‚ö†Ô∏è  Warning: Split folder '{split_name}' not found in raw_data. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nüìÇ Processing SPLIT: {split_name.upper()}\")\n",
    "        \n",
    "        # Determine the file limit for this split\n",
    "        # (We usually cap training at 1000, but keep test sets smaller or as-is)\n",
    "        limit = MAX_FILES_TRAIN if split_name == 'train' else MAX_FILES_TEST\n",
    "\n",
    "        # Get classes inside this split folder\n",
    "        classes = sorted([d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path, d))])\n",
    "        \n",
    "        for class_name in classes:\n",
    "            # Setup paths\n",
    "            source_dir = os.path.join(split_path, class_name)\n",
    "            target_dir = os.path.join(OUTPUT_ROOT, split_name, class_name)\n",
    "            os.makedirs(target_dir, exist_ok=True)\n",
    "            \n",
    "            # Get files\n",
    "            files = glob.glob(os.path.join(source_dir, \"*\"))\n",
    "            files = [f for f in files if f.lower().endswith(('.wav', '.mp3', '.flac'))]\n",
    "            \n",
    "            # --- BALANCING ---\n",
    "            if len(files) > limit:\n",
    "                print(f\"   üî∏ {class_name}: {len(files)} -> Capping at {limit}\")\n",
    "                random.shuffle(files)\n",
    "                selected_files = files[:limit]\n",
    "            else:\n",
    "                print(f\"   üîπ {class_name}: {len(files)} (Kept all)\")\n",
    "                selected_files = files\n",
    "                \n",
    "            # --- PROCESSING ---\n",
    "            for file_path in tqdm(selected_files, desc=f\"     Processing {class_name}\", leave=False):\n",
    "                filename = os.path.basename(file_path)\n",
    "                dst_filename = os.path.splitext(filename)[0] + \".wav\"\n",
    "                dst_path = os.path.join(target_dir, dst_filename)\n",
    "                \n",
    "                success = preprocess_audio(file_path, dst_path)\n",
    "                \n",
    "                if success:\n",
    "                    processed_records.append({\n",
    "                        'file_path': dst_path,\n",
    "                        'label_name': class_name,\n",
    "                        'split': split_name  # Crucial: We save which split it belongs to\n",
    "                    })\n",
    "\n",
    "    # --- SAVE FINAL INDEX ---\n",
    "    df = pd.DataFrame(processed_records)\n",
    "    \n",
    "    # Create integer mappings for classes\n",
    "    unique_classes = sorted(df['label_name'].unique())\n",
    "    label_map = {name: i for i, name in enumerate(unique_classes)}\n",
    "    df['label_idx'] = df['label_name'].map(label_map)\n",
    "\n",
    "    df.to_csv(CSV_FILENAME, index=False)\n",
    "    print(f\"\\n‚úÖ Done! Data saved to '{OUTPUT_ROOT}'\")\n",
    "    print(f\"üìù Index saved to '{CSV_FILENAME}'\")\n",
    "    print(f\"   Total Files: {len(df)}\")\n",
    "    print(df['split'].value_counts())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfdd768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü©∫ Starting Clinical Feature Extraction (This may take a moment)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4817/4817 [02:09<00:00, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extraction Complete!\n",
      "   Features saved to: 'sfm_features.csv'\n",
      "   Original Files: 4817 -> Successfully Processed: 4817\n",
      "   (Dropped files were likely too short or silent for Praat to analyze)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_CSV = \"dataset_final.csv\"\n",
    "OUTPUT_CSV = \"sfm_features.csv\"\n",
    "\n",
    "def extract_features(file_path):\n",
    "    \"\"\"\n",
    "    Extracts 18 clinical features using Praat (Parselmouth).\n",
    "    Returns a dictionary of features or None if extraction fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load Sound\n",
    "        sound = parselmouth.Sound(file_path)\n",
    "        \n",
    "        # 1. Pitch & HNR Analysis\n",
    "        pitch = sound.to_pitch()\n",
    "        pulses = parselmouth.praat.call([sound, pitch], \"To PointProcess (cc)\")\n",
    "        \n",
    "        # HNR (Harmonics to Noise Ratio)\n",
    "        harmonicity = sound.to_harmonicity()\n",
    "        hnr = call(harmonicity, \"Get mean\", 0, 0)\n",
    "        \n",
    "        # 2. Jitter (Frequency Perturbation)\n",
    "        jitter_local = call(pulses, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "        jitter_rap   = call(pulses, \"Get jitter (rap)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "        \n",
    "        # 3. Shimmer (Amplitude Perturbation)\n",
    "        shimmer_local = call([sound, pulses], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        shimmer_apq3  = call([sound, pulses], \"Get shimmer (apq3)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "        \n",
    "        # 4. Formants (F1, F2, F3, F4) - The \"Filter\"\n",
    "        # We look for 5 formants up to 5500Hz (standard for adult voice)\n",
    "        formant = sound.to_formant_burg(time_step=0.01, max_number_of_formants=5, maximum_formant=5500.0)\n",
    "        \n",
    "        f1 = call(formant, \"Get mean\", 1, 0, 0, \"Hertz\")\n",
    "        f2 = call(formant, \"Get mean\", 2, 0, 0, \"Hertz\")\n",
    "        f3 = call(formant, \"Get mean\", 3, 0, 0, \"Hertz\")\n",
    "        f4 = call(formant, \"Get mean\", 4, 0, 0, \"Hertz\")\n",
    "        \n",
    "        # 5. Basic Stats\n",
    "        f0_mean = call(pitch, \"Get mean\", 0, 0, \"Hertz\")\n",
    "        \n",
    "        # Handle \"NaN\" (Silent files or errors) - replace with 0\n",
    "        features = {\n",
    "            'jitter_local': jitter_local,\n",
    "            'jitter_rap': jitter_rap,\n",
    "            'shimmer_local': shimmer_local,\n",
    "            'shimmer_apq3': shimmer_apq3,\n",
    "            'hnr': hnr,\n",
    "            'f1': f1,\n",
    "            'f2': f2,\n",
    "            'f3': f3,\n",
    "            'f4': f4,\n",
    "            'f0_mean': f0_mean\n",
    "        }\n",
    "        \n",
    "        # Clean NaNs (Parselmouth returns 'nan' if voice is too quiet)\n",
    "        return {k: (0.0 if np.isnan(v) else v) for k, v in features.items()}\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INPUT_CSV):\n",
    "        print(f\"‚ùå Error: '{INPUT_CSV}' not found. Run Phase 1 first.\")\n",
    "        return\n",
    "\n",
    "    print(\"ü©∫ Starting Clinical Feature Extraction (This may take a moment)...\")\n",
    "    \n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "    \n",
    "    # Storage for features\n",
    "    extracted_data = []\n",
    "    \n",
    "    # Iterate through every file in our index\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        file_path = row['file_path']\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            feats = extract_features(file_path)\n",
    "            if feats:\n",
    "                # Add file_path to link it back later\n",
    "                feats['file_path'] = file_path\n",
    "                extracted_data.append(feats)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: File missing {file_path}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    sfm_df = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    # Merge with original info (Labels/Splits) so we have a Single Master Training CSV\n",
    "    final_df = pd.merge(df, sfm_df, on='file_path', how='inner')\n",
    "    \n",
    "    # Save\n",
    "    final_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Extraction Complete!\")\n",
    "    print(f\"   Features saved to: '{OUTPUT_CSV}'\")\n",
    "    print(f\"   Original Files: {len(df)} -> Successfully Processed: {len(final_df)}\")\n",
    "    print(\"   (Dropped files were likely too short or silent for Praat to analyze)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fd505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your_env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
